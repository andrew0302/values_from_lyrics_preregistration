---
title: "time_per_item"
author: "andrew demetriou"
date: "11/29/2021"
---

#AIM

The aim of this notebook is to examine how long it took to answer the items on the lyrics questionnaire, and to complete each set of questions for each song lyric. 


```{r setup, include=FALSE}
library('here')       # file logistics
library('data.table') # data manipulation
library('dplyr')      # data manipulation
library('ggplot2')    # data visualization
library('gridExtra')  # data visualization
library('forcats')    # ordering factors
library('shiny')      # interactive visualization
library('DT')         # interactive visualization
```

```{r}
load(here("VI_data_collection_november_2022", "intermediary_data", "working_df.RDS"))
responses_dt <- as.data.table(working_df)

# replace missing values with NA
responses_dt[Age=="DATA_EXPIRED"] <- NA

# not sure what this is meant to indicate
# treat as missing
responses_dt[Age=="1022"] <- NA
```


```{r}
# coerce to numeric
responses_dt$Age <- as.numeric(responses_dt$Age)

# plot histogram
responses_dt |>
  ggplot(aes(x=Age)) +
  geom_histogram(bins=50)

# median age is 40
median(responses_dt$Age, na.rm=TRUE)
```

Both prolific and qualtrics have their own measures of time taken for the entire survey. Here I take a look at each of them. 

```{r}
#rename qualtrics duration column
responses_dt$duration <- as.numeric(responses_dt$`Duration (in seconds)`) 

#define columns to plot
columns <- c("duration", "participant_ID", "Time taken", "Sex", "Age")

#plot survey duration according to qualtrics
duration_plot <- responses_dt %>% select(columns) %>%
  ggplot(., aes(x=duration, y=Age, color=Sex)) +
  geom_point() +
  xlab("Time (in seconds): Qualtrics") +
  scale_x_continuous(limits = c(1000, 7000))

#plot survey duration according to prolific
responses_dt$`Time taken` <- as.numeric(responses_dt$`Time taken`)
time_taken_plot <- responses_dt %>% 
  select(columns) %>%
  ggplot(., aes(x=`Time taken`, y=Age, color=Sex)) +
  geom_point() +
  xlab("Time (in seconds): Prolific") +
  scale_x_continuous(limits = c(1000, 7000))

grid.arrange(duration_plot, time_taken_plot, ncol=1)

rm(duration_plot, time_taken_plot, columns)
```
Qualtrics recorded some very long durations that appear to be errors. 

```{r}
# create df with single row for each participant
time_taken_df <- responses_dt %>% 
  group_by(participant_ID) %>%
  summarize(`Time taken`, duration) %>%
  unique() %>%
  as.data.table()

# values as high as 100k look like timeouts

time_taken_hist <- time_taken_df %>% ggplot(aes(x=`Time taken`)) +
  geom_histogram() +
  xlab("Time (in seconds): Prolific")

duration_hist <- time_taken_df[duration<10000,] %>% ggplot(aes(x=duration)) +
  geom_histogram() +
  xlab("Time (in seconds): Qualtrics")


grid.arrange(duration_hist, time_taken_hist, ncol=1)

rm(time_taken_hist, duration_hist, time_taken_df)
```



```{r}
# create an outliers dataset to examine participant responses
outliers_dt <- responses_dt[`Time taken`>5000 | duration>5000]

# responses look legit

rm(outliers_dt)
```

Here I select rows that have the timing information for each of the questions. Specifically, I select rows with that contain a) the first click on the page, and b) the last click on the page. I then subtract the first click time from the last click time to get the time spent on the page. 

According to: https://www.qualtrics.com/support/survey-platform/survey-module/editing-questions/question-types-guide/advanced/timing/, the time is in seconds. 


```{r}
# logical vector of matches to: 
# 1) either first or last click for a question
# 2) participant ID
# 3) the song id
clicks <- grepl("m_First Click|m_Last Click|participant_ID|song|Age|Sex", colnames(responses_dt)) 

# subset data based on clicks vector
clicks_dt <- responses_dt[, ..clicks]

# time taken per song
clicks_dt <- clicks_dt[, diff := (as.numeric(`m_Last Click`) - as.numeric(`m_First Click`))]
```


```{r}
# create a df of median time taken for songs
time_taken_table <- clicks_dt |> 
  group_by(song) |>
  summarize(mean = mean(diff, na.rm=T), median = median(diff, na.rm=T), sd = sd(diff, na.rm=T)) |>
  # descending order by median
  arrange(desc(median))

songs <- head(time_taken_table$song, 40)

long_diff_dt <- clicks_dt[song %in% songs]

long_diff_dt %>% 
  ggplot(., aes(x=diff, y=song, color = song)) +
  geom_boxplot(show.legend=FALSE) +
  theme_minimal() +
  xlab("Time taken (In seconds)")

rm(time_taken_table, songs, long_diff_dt)
```


Here I table the time taken per observation in descending order:

```{r}
clicks_dt[order(-diff),]

clicks_dt$participant_ID <- factor(clicks_dt$participant_ID) |>
  fct_reorder(clicks_dt$diff, na.rm=TRUE)

clicks_dt |>
  ggplot(aes(y=diff, x=participant_ID)) +
  geom_col()
```

Here I filter out the initial lyrics questionnaire and estimate central tendency of the time taken per lyric. 

```{r}
no_outliers_removed <- clicks_dt |>
  summarize(mean = mean(diff, na.rm=T), median = median(diff, na.rm=T), sd = sd(diff, na.rm=T))

outliers_less_than_200 <- clicks_dt[diff<200] |>
  summarize(mean = mean(diff), median=median(diff), sd = sd(diff))

central_tendency <- rbind(no_outliers_removed, outliers_less_than_200)
central_tendency$outliers <- c("no outliers removed", "outliers set at < 200")
central_tendency <- central_tendency |> select(outliers, everything())
central_tendency

rm(no_outliers_removed, outliers_less_than_200, central_tendency)
```

To more closely examine whether older people take more time, I plot the time taken variable against age:

```{r}
clicks_dt[diff<1000] |>
  ggplot(aes(x=diff, y=Age, color=Sex)) +
  geom_point()
```

Although there's no reason to expect sex differences I plot them anyway:
```{r}
clicks_dt[Sex == "CONSENT_REVOKED"] <- NA

clicks_dt[diff<900] %>% 
  filter(!is.na(Sex)) %>%
  ggplot(aes(x=diff, color=Sex, fill=Sex)) +
  geom_histogram() +
  facet_wrap(~Sex)

clicks_dt[diff<900] %>% ggplot(aes(x=diff)) +
  geom_histogram(bins = 30) +
  geom_vline(aes(xintercept = median(diff)), color="red") +
  annotate(geom="text", x=200, y=4000, label="Median = 31.8") +
  xlab("Time (in seconds")
```

Here I build a data table of the mean time taken per question block, excluding outliers defined as > 900 seconds. 

```{r}
# create summary table
summary_dt <- clicks_dt %>% group_by(song) %>% summarize(mean = mean(diff), sd = sd(diff)) %>% ungroup()

summary_dt |> ggplot(aes(mean)) +
  geom_histogram()

#compute mean and sd seconds per lyric stimulus
summary_dt %>% summarize(mean = mean(mean, na.rm=T), sd=mean(sd, na.rm=T))

#create summary statistics dt by questionnaire section
summary_dt <- clicks_dt[diff<200] %>% group_by(song) %>% summarize(mean = mean(diff), sd = sd(diff)) %>% ungroup()

#make data table
setDT(summary_dt)
```
 
```{r}
summary_dt[order(-mean),]
summary_dt[order(-sd),]
```

More interactive visualization below:

```{r}
ui <- fluidPage(
  titlePanel("Time Taken by Song (in seconds)"),
  
  #plot this thing called 'alpha_plot'
  plotOutput('clicks_dt_plot'),
  
  #tableOutput('alpha_table')
  DT::DTOutput('clicks_dt')
)

server <- function(input, output, session){
  
  # render the plots; alpha distribution by n
  output$clicks_dt_plot <- renderPlot({
    clicks_dt[diff > 0 & diff < 200,] %>% 
    ggplot(., aes(x=diff, y=song, color = song)) +
    geom_boxplot(show.legend=FALSE) +
    theme_minimal() +
    #this adds the label to the title
    labs(title=paste("Time Taken by Song (in seconds)"))
  })
  
  # render the table of minimum n alpha summaries
  output$clicks_dt <- renderDataTable(clicks_dt[diff > 0 & diff < 200,])
}
shinyApp(ui=ui, server=server)
```


